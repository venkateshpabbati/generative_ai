{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "550f42da-6d38-4047-8714-d1dc0f454ffb",
   "metadata": {},
   "source": [
    "# Grade calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2189f60-f17b-41a0-9189-defd1b1bfb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of subjects 3\n",
      "Enter the subject 1 name:  Maths\n",
      "Enter score for Maths (out of 100):  80\n",
      "Enter the subject 2 name:  Science\n",
      "Enter score for Science (out of 100):  80\n",
      "Enter the subject 3 name:  Social\n",
      "Enter score for Social (out of 100):  80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 80.0\n",
      "Grade: B\n",
      "Eligible for Honors: No\n"
     ]
    }
   ],
   "source": [
    "number_of_subjects = int(input(\"Enter the number of subjects\")) # take input number of subjects\n",
    "total_score = 0 # initializing with 0\n",
    "for i in range(1,number_of_subjects+1): # loop with number of subjects\n",
    "    subject_name = input(f\"Enter the subject {i} name: \") # take input the subject name\n",
    "    score = int(input(f\"Enter score for {subject_name} (out of 100): \")) # takes input the marks of respective subject\n",
    "    total_score += score # calculates total score\n",
    "average_score = total_score / number_of_subjects # calculates average score af all subjects\n",
    "print(f\"Average Score: {average_score}\")\n",
    "grade = None \n",
    "honors = 'No'\n",
    "# condition to give the grade to subject\n",
    "if average_score >= 90:\n",
    "    grade = 'A'\n",
    "    honors = 'Yes'\n",
    "elif average_score >= 80:\n",
    "    grade = 'B'\n",
    "elif average_score >=70:\n",
    "    grade = 'C'\n",
    "elif average_score >= 60:\n",
    "    grade = 'D'\n",
    "else:\n",
    "    grade = 'F'\n",
    "# print the grade and honor whether eligible or not\n",
    "print(f\"Grade: {grade}\")\n",
    "print(f\"Eligible for Honors: {honors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d22aad3-32d2-4995-9740-8f0a75ee0179",
   "metadata": {},
   "source": [
    "# Word Frequency Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26835e70-79a4-47f9-b345-31f6ddb1002a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence or paragraph:  Venkatesh Pabbati\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pabbati: 1\n",
      "venkatesh: 1\n"
     ]
    }
   ],
   "source": [
    "# Take input paragraph or sentence and convert to lowercase\n",
    "paragraph = input(\"Enter a sentence or paragraph: \").lower()\n",
    "\n",
    "# Defining the punctuation which are to be removed\n",
    "punctuation = '''!()-[]{};:'\",<>./?@#$%^&*_~'''  # Removed the backslash\n",
    "\n",
    "# Remove punctuations\n",
    "cleaned_para = ''.join(char if char not in punctuation else ' ' for char in paragraph)\n",
    "\n",
    "# Tokenize\n",
    "words = cleaned_para.split()\n",
    "\n",
    "# Loop to store word and count in dictionary\n",
    "word_count = {}\n",
    "for word in words:\n",
    "    if word in word_count:\n",
    "        word_count[word] += 1\n",
    "    else:\n",
    "        word_count[word] = 1\n",
    "\n",
    "# Print the word counter in alphabetical sorted manner\n",
    "for word, count in sorted(word_count.items()):\n",
    "    print(f'{word}: {count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7922e3d-28bb-41b6-93c8-a87fb22cf818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence or paragraph:  Venkatesh Pabbati\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pabbati: 1\n",
      "venkatesh: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Take input paragraph or sentence and convert to lowercase\n",
    "paragraph = input(\"Enter a sentence or paragraph: \").lower()\n",
    "\n",
    "# Define the punctuation to be removed\n",
    "punctuation = '''!()-[]{};:'\",<>./?@#$%^&*_~'''\n",
    "\n",
    "# Remove punctuations and tokenize\n",
    "cleaned_para = ''.join(char if char not in punctuation else ' ' for char in paragraph).split()\n",
    "\n",
    "# Count word occurrences using defaultdict for cleaner code\n",
    "word_count = defaultdict(int)\n",
    "for word in cleaned_para:\n",
    "    word_count[word] += 1\n",
    "\n",
    "# Print the word counter in alphabetical sorted manner\n",
    "for word, count in sorted(word_count.items()):\n",
    "    print(f'{word}: {count}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae8d977-40b5-4347-b5c1-342ca7d5a3d4",
   "metadata": {},
   "source": [
    "Code with Stopword Removal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfaad771-79c8-4fba-b0a0-d857afa2e431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\venka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence or paragraph:  I am Venkatesh Pabbati working professional having no experience in IT domain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domain: 1\n",
      "experience: 1\n",
      "pabbati: 1\n",
      "professional: 1\n",
      "venkatesh: 1\n",
      "working: 1\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download the stopwords list if you haven't already\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Take input paragraph or sentence and convert to lowercase\n",
    "paragraph = input(\"Enter a sentence or paragraph: \").lower()\n",
    "\n",
    "# Define the punctuation to be removed\n",
    "punctuation = '''!()-[]{};:'\",<>./?@#$%^&*_~'''\n",
    "\n",
    "# Remove punctuations and tokenize\n",
    "cleaned_para = ''.join(char if char not in punctuation else ' ' for char in paragraph).split()\n",
    "\n",
    "# Get English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Remove stopwords\n",
    "filtered_words = [word for word in cleaned_para if word not in stop_words]\n",
    "\n",
    "# Count word occurrences using defaultdict for cleaner code\n",
    "word_count = defaultdict(int)\n",
    "for word in filtered_words:\n",
    "    word_count[word] += 1\n",
    "\n",
    "# Print the word counter in alphabetical sorted manner\n",
    "for word, count in sorted(word_count.items()):\n",
    "    print(f'{word}: {count}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094e890a-a558-4670-ae2f-d6cf0718d59c",
   "metadata": {},
   "source": [
    "Enhanced Code with Additional Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "247b33c5-b210-4563-83f5-1683478b2cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\venka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\venka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence or paragraph:  I am Venkatesh Pabbati working professional having no experience in IT domain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domain: 1\n",
      "experi: 1\n",
      "pabbati: 1\n",
      "profession: 1\n",
      "venkatesh: 1\n",
      "work: 1\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "\n",
    "# Download the necessary NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize the stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Take input paragraph or sentence and convert to lowercase\n",
    "paragraph = input(\"Enter a sentence or paragraph: \").lower()\n",
    "\n",
    "# Define the punctuation to be removed\n",
    "punctuation = '''!()-[]{};:'\",<>./?@#$%^&*_~'''\n",
    "\n",
    "# Remove punctuation and tokenize, and remove numbers\n",
    "cleaned_para = ''.join(char if char not in punctuation else ' ' for char in paragraph)\n",
    "cleaned_para = re.sub(r'\\d+', '', cleaned_para)  # Remove digits\n",
    "cleaned_para = cleaned_para.split()\n",
    "\n",
    "# Get English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Apply preprocessing: Remove stopwords, apply stemming, and remove extra whitespace\n",
    "processed_words = []\n",
    "for word in cleaned_para:\n",
    "    if word not in stop_words:  # Remove stopwords\n",
    "        stemmed_word = stemmer.stem(word)  # Apply stemming\n",
    "        processed_words.append(stemmed_word)\n",
    "\n",
    "# Count word occurrences using defaultdict\n",
    "word_count = defaultdict(int)\n",
    "for word in processed_words:\n",
    "    word_count[word] += 1\n",
    "\n",
    "# Print the word counter in alphabetical sorted manner\n",
    "for word, count in sorted(word_count.items()):\n",
    "    print(f'{word}: {count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a450d75e-6888-4f93-9d4a-b4e39c62aed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
